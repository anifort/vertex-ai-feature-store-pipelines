{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "2b732f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import time, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "177310bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    Input,\n",
    "    Output,\n",
    "    Dataset,\n",
    "    Metrics,\n",
    "    Artifact,\n",
    "    Model,\n",
    "    ClassificationMetrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "975f4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=[\"google-cloud-bigquery==2.24.1\"])\n",
    "def data_selector(\n",
    "    query: str,\n",
    "    bq_project_id: str,\n",
    "    bq_dataset_id: str,\n",
    "    bq_table_id: str,\n",
    "    bq_location: str,\n",
    "    table_dataset: Output[Dataset]\n",
    ") -> None:\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "    import logging\n",
    "    \n",
    "    bq_query_data_table=\"{project}.{dataset}.{table}\".format(\n",
    "        project=bq_project_id, \n",
    "        dataset=bq_dataset_id, \n",
    "        table=bq_table_id)\n",
    "\n",
    "    client = bigquery.Client(project=bq_project_id, location=bq_location,)\n",
    "\n",
    "    overwrite_table = False\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        write_disposition = bigquery.job.WriteDisposition.WRITE_TRUNCATE if overwrite_table else bigquery.job.WriteDisposition.WRITE_EMPTY,\n",
    "        destination = bq_query_data_table)\n",
    "\n",
    "    try:\n",
    "        query_job = client.query(query = query, \n",
    "                                 job_config = job_config)\n",
    "        query_job.result()\n",
    "        #if .total_rows == 0:\n",
    "        #    raise Exception(\"Query return no rows\".format(bq_query_data_table))\n",
    "\n",
    "        if query_job.errors: \n",
    "            raise Exception() \n",
    "    except Exception as e:\n",
    "        logging.error(query_job.errors)\n",
    "        raise e\n",
    "\n",
    "    \n",
    "\n",
    "    table = client.get_table(bq_query_data_table)  # Make an API request.\n",
    "    table_dataset.path = \"bq://{}\".format(bq_query_data_table)\n",
    "    table_dataset.metadata['table_name'] = bq_query_data_table\n",
    "    \n",
    "    print(vars(table_dataset))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# View table properties\n",
    "#print(\"Table schema: {}\".format(table.schema))\n",
    "#print(\"Table description: {}\".format(table.description))\n",
    "#print(\"Table has {} rows\".format(table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "3e99484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "\n",
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT planet as planets, terrestrial_date as timestamp, 5 as pt\n",
    "        FROM `feature-store-mars21.mars.three_planets_tmp` WHERE 1=1\n",
    "    \"\"\"\n",
    "\n",
    "bq_location = 'US'\n",
    "bq_project_id = \"feature-store-mars21\"\n",
    "bq_dataset_id = \"mars\"\n",
    "bq_table_id = \"tmp-table-v13\"\n",
    "\n",
    "bq_export_table_id = \"training-v1\"\n",
    "    \n",
    "\n",
    "BUCKET_NAME = \"gs://feature-store-mars21\"\n",
    "@dsl.pipeline(\n",
    "  name='bq-fs-export',\n",
    "  description='',\n",
    "  pipeline_root=BUCKET_NAME+\"/xgb-pl\"\n",
    ")\n",
    "def pipeline(\n",
    "    query: str,\n",
    "    bq_project_id: str,\n",
    "    bq_dataset_id: str,\n",
    "    bq_table_id: str,\n",
    "    bq_location: str\n",
    "):\n",
    "    \n",
    "    prepro_op = data_selector(\n",
    "        query,\n",
    "        bq_project_id,\n",
    "        bq_dataset_id,\n",
    "        bq_table_id,\n",
    "        bq_location)\n",
    "    \n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"pl.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "13005d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "\n",
    "params['query'] = \"\"\"\n",
    "    SELECT planet as planets, terrestrial_date as timestamp, 5 as pt\n",
    "        FROM `feature-store-mars21.mars.three_planets_tmp` WHERE 1=1\n",
    "    \"\"\"\n",
    "\n",
    "params['bq_location'] = 'US'\n",
    "params['bq_project_id'] = \"feature-store-mars21\"\n",
    "params['bq_dataset_id'] = \"mars\"\n",
    "params['bq_table_id'] = \"tmp-table-v15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "1ecf5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform.pipeline_jobs import PipelineJob\n",
    "\n",
    "\n",
    "pl = PipelineJob(\n",
    "        display_name= 'bq-fs-export',\n",
    "        template_path= \"pl.json\",\n",
    "        location='us-central1',\n",
    "        parameter_values=params)\n",
    "\n",
    "pl.run(sync=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "739b036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if table.num_rows==0:\n",
    "    raise Exception(\"BQ table {} has no rows. Ensure thet your query returns results: {}\".format(bq_query_data_table, query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "6c7fa5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict # in case dict is not created using python>=3.6\n",
    "schema = OrderedDict((i.name,i.field_type) for i in table.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "eaff0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_type_cols = []\n",
    "pass_through_cols = []\n",
    "reading_entity_types=True\n",
    "for key, value in schema.items():\n",
    "    if key=='timestamp':\n",
    "        reading_entity_types=False\n",
    "        if value!=\"TIMESTAMP\":\n",
    "            raise ValueError(\"timestamp column must be of type TIMESTAMP\")\n",
    "    else:\n",
    "        if reading_entity_types==True:\n",
    "            entity_type_cols.append(key)\n",
    "        else:\n",
    "            pass_through_cols.append(key)\n",
    "        \n",
    "if reading_entity_types==True: # means timestamp column was not found so this remained False\n",
    "    raise ValueError(\"timestamp column missing from BQ table. It is required for feature store data retrieval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "2031c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['planets']"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_type_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "9b851b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pt']"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_through_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "5006c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate entity types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "76a338d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_location = 'us-central1'\n",
    "fs_project = 'feature-store-mars21'\n",
    "fs_featurestore_name = 'universe'\n",
    "\n",
    "fs_path= 'projects/{fs_project}/locations/{fs_location}/featurestores/{fs_name}'.format(fs_project=fs_project,\n",
    "                                                   fs_location=fs_location,\n",
    "                                                   fs_name=fs_featurestore_name)\n",
    "    \n",
    "from google.cloud.aiplatform_v1beta1 import FeaturestoreServiceClient\n",
    "\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(fs_location)\n",
    "\n",
    "admin_client = FeaturestoreServiceClient(\n",
    "    client_options={\"api_endpoint\": API_ENDPOINT})\n",
    "\n",
    "fs_entities = admin_client.list_entity_types(parent=fs_path).entity_types\n",
    "\n",
    "fs_entities = [i.name.split('/')[-1] for i in fs_entities]\n",
    "\n",
    "if len(set(entity_type_cols).difference(fs_entities))>0:\n",
    "    raise ValueError(\"Table column(s) {} before timestamp column do not match entities in feature store {} \".format(entity_type_cols, fs_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "3278c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from BQ and export to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "cbd2f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features to retrieve for each entity type\n",
    "my_features  = {'planets': [\"avg_max_temp_5d\", \"arr_max_temp_3d\", \"min_temp_std\"]}\n",
    "feature_diff = set(my_features.keys()).difference(entity_type_cols)\n",
    "if len(feature_diff)>0:\n",
    "    raise LookupError(\"Features requested for entities {} that does not exist in filtering query columns: {} \".format(feature_diff, query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "be35ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bq_export_data_table=\"{project}.{dataset}.{table}\".format(\n",
    "    project=bq_project_id, \n",
    "    dataset=bq_dataset_id, \n",
    "    table=bq_export_table_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "entity_type_cols\n",
    "\n",
    "entity_type_specs_arr=[]\n",
    "\n",
    "# Select features to read\n",
    "for ent_type, features_arr in my_features.items():\n",
    "    entity_type_specs_arr.append(\n",
    "        featurestore_service_pb2.BatchReadFeatureValuesRequest.EntityTypeSpec(\n",
    "            # read feature values of features subscriber_type and duration_minutes from \"bikes\"\n",
    "            entity_type_id= ent_type, \n",
    "            feature_selector= feature_selector_pb2.FeatureSelector(\n",
    "                id_matcher=feature_selector_pb2.IdMatcher(\n",
    "                ids=features_arr))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "batch_serving_request = featurestore_service_pb2.BatchReadFeatureValuesRequest(\n",
    "    featurestore=fs_path,\n",
    "    bigquery_read_instances=BigQuerySource(input_uri = \"bq://{}\".format(bq_query_data_table)),\n",
    "    #csv_read_instances=io_pb2.CsvSource(\n",
    "    #    gcs_source=io_pb2.GcsSource(uris=[FEATURE_REQ_CSV_PATH])),\n",
    "    \n",
    "    # Output info\n",
    "    destination=featurestore_service_pb2.FeatureValueDestination(\n",
    "        bigquery_destination=io_pb2.BigQueryDestination(\n",
    "            # output to BigQuery table\n",
    "            output_uri='bq://{}'.format(bq_export_data_table))),\n",
    "    #destination=featurestore_service_pb2.FeatureValueDestination(\n",
    "    #    tfrecord_destination=io_pb2.CsvDestination(\n",
    "    #        gcs_destination=EXPORT_TF_PATH)),\n",
    "    \n",
    "   entity_type_specs=entity_type_specs_arr\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "233f05bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409 Destination Table `bq://feature-store-mars21.mars.training-v1` must not exist.\n",
      "CPU times: user 0 ns, sys: 4.2 ms, total: 4.2 ms\n",
      "Wall time: 999 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    print(admin_client.batch_read_feature_values(batch_serving_request).result())\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9fd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m79"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
